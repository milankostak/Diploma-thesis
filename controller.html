<!DOCTYPE html>
<html lang="en-GB" dir="ltr">
<head>
<meta charset="UTF-8">
<title>Controller</title>
<link rel="stylesheet" type="text/css" href="/css/controller.css">
<script type="text/javascript" src="/js/transforms3d.js"></script>
<script type="text/javascript" src="/js/webgl-utils.js"></script>
<script type="text/javascript" src="/js/sender.js"></script>
<script type="text/javascript" src="/js/detection.js"></script>
<script type="text/javascript" src="/js/rotation.js"></script>
<script type="text/javascript" src="/js/motion.js"></script>
<script type="text/javascript" src="/js/helpers.js"></script>
<script id="shader-fs1" type="x-shader/x-fragment">
	precision mediump float;

	uniform sampler2D texture;
	uniform float width;//w4
	uniform float height;//h4

	varying vec2 textureCoord;

	uniform vec3 targetColor;// = vec3(0.2, 0.8, 0.2);
	const float thr = 0.25;

	bool correctPixel(vec4 pixel) {

//		float thresholdG = 0.6;
//		float thresholdRB = 0.4;
//		if (pixel.g > thresholdG && pixel.r < thresholdRB && pixel.b < thresholdRB) {
		if (pixel.r > targetColor.r - thr && pixel.r < targetColor.r + thr &&
			pixel.g > targetColor.g - thr && pixel.g < targetColor.g + thr &&
			pixel.b > targetColor.b - thr && pixel.b < targetColor.b + thr) {
			return true;
		} else {
			return false;
		}
	}

	void main(void) {
		// get current real coordinates
		float x = floor(textureCoord.x * width);
		float y = floor(textureCoord.y * height);

		// base top left coordinates of given square
		// taking every fourth pixel
		float baseX = x - mod(x, 4.0);
		float baseY = y - mod(y, 4.0);

		// distance between 2 pixels in general
		vec2 diff = vec2(1.0/width, 1.0/height);

		// actual texture coordinates of top left pixel
		// + diff/2 because textureCoord is always between numbers
		vec2 baseTextureCoord = vec2(baseX / width + diff.x / 2.0, baseY / height + diff.y / 2.0);

		// get all 16 pixels in given square
		// done this way because when making the texture smaller, browsers were returning different sampled coordinates (Firefox and Chrome)
		// doing it like this means all 16 pixels have the same values and it doesn't matter anymore which one is picked by browser
		vec4 pix00 = texture2D(texture, vec2(baseTextureCoord.x, baseTextureCoord.y));
		vec4 pix10 = texture2D(texture, vec2(baseTextureCoord.x + diff.x, baseTextureCoord.y));
		vec4 pix20 = texture2D(texture, vec2(baseTextureCoord.x + 2.0*diff.x, baseTextureCoord.y));
		vec4 pix30 = texture2D(texture, vec2(baseTextureCoord.x + 3.0*diff.x, baseTextureCoord.y));
		//vec4 pix40 = texture2D(texture, vec2(baseTextureCoord.x + 4.0*diff.x, baseTextureCoord.y));

		vec4 pix01 = texture2D(texture, vec2(baseTextureCoord.x, baseTextureCoord.y + diff.y));
		vec4 pix11 = texture2D(texture, vec2(baseTextureCoord.x + diff.x, baseTextureCoord.y + diff.y));
		vec4 pix21 = texture2D(texture, vec2(baseTextureCoord.x + 2.0*diff.x, baseTextureCoord.y + diff.y));
		vec4 pix31 = texture2D(texture, vec2(baseTextureCoord.x + 3.0*diff.x, baseTextureCoord.y + diff.y));
		//vec4 pix41 = texture2D(texture, vec2(baseTextureCoord.x + 4.0*diff.x, baseTextureCoord.y + diff.y));

		vec4 pix02 = texture2D(texture, vec2(baseTextureCoord.x, baseTextureCoord.y + 2.0*diff.y));
		vec4 pix12 = texture2D(texture, vec2(baseTextureCoord.x + diff.x, baseTextureCoord.y + 2.0*diff.y));
		vec4 pix22 = texture2D(texture, vec2(baseTextureCoord.x + 2.0*diff.x, baseTextureCoord.y + 2.0*diff.y));
		vec4 pix32 = texture2D(texture, vec2(baseTextureCoord.x + 3.0*diff.x, baseTextureCoord.y + 2.0*diff.y));
		//vec4 pix42 = texture2D(texture, vec2(baseTextureCoord.x + 4.0*diff.x, baseTextureCoord.y + 2.0*diff.y));

		vec4 pix03 = texture2D(texture, vec2(baseTextureCoord.x, baseTextureCoord.y + 3.0*diff.y));
		vec4 pix13 = texture2D(texture, vec2(baseTextureCoord.x + diff.x, baseTextureCoord.y + 3.0*diff.y));
		vec4 pix23 = texture2D(texture, vec2(baseTextureCoord.x + 2.0*diff.x, baseTextureCoord.y + 3.0*diff.y));
		vec4 pix33 = texture2D(texture, vec2(baseTextureCoord.x + 3.0*diff.x, baseTextureCoord.y + 3.0*diff.y));
		//vec4 pix43 = texture2D(texture, vec2(baseTextureCoord.x + 4.0*diff.x, baseTextureCoord.y + 3.0*diff.y));

		//vec4 pix04 = texture2D(texture, vec2(baseTextureCoord.x, baseTextureCoord.y + 4.0*diff.y));
		//vec4 pix14 = texture2D(texture, vec2(baseTextureCoord.x + diff.x, baseTextureCoord.y + 4.0*diff.y));
		//vec4 pix24 = texture2D(texture, vec2(baseTextureCoord.x + 2.0*diff.x, baseTextureCoord.y + 4.0*diff.y));
		//vec4 pix34 = texture2D(texture, vec2(baseTextureCoord.x + 3.0*diff.x, baseTextureCoord.y + 4.0*diff.y));
		//vec4 pix44 = texture2D(texture, vec2(baseTextureCoord.x + 4.0*diff.x, baseTextureCoord.y + 4.0*diff.y));

		float thresholdG = 0.6;
		float thresholdRB = 0.4;
		float count = 0.0;

		// count it as pixel of interest only if green is high enough and red & blue not too much
		if (correctPixel(pix00)) count += 1.0;
		if (correctPixel(pix10)) count += 1.0;
		if (correctPixel(pix20)) count += 1.0;
		if (correctPixel(pix30)) count += 1.0;
		//if (correctPixel(pix40)) count += 1.0;

		if (correctPixel(pix01)) count += 1.0;
		if (correctPixel(pix11)) count += 1.0;
		if (correctPixel(pix21)) count += 1.0;
		if (correctPixel(pix31)) count += 1.0;
		//if (correctPixel(pix41)) count += 1.0;

		if (correctPixel(pix02)) count += 1.0;
		if (correctPixel(pix12)) count += 1.0;
		if (correctPixel(pix22)) count += 1.0;
		if (correctPixel(pix32)) count += 1.0;
		//if (correctPixel(pix42)) count += 1.0;

		if (correctPixel(pix03)) count += 1.0;
		if (correctPixel(pix13)) count += 1.0;
		if (correctPixel(pix23)) count += 1.0;
		if (correctPixel(pix33)) count += 1.0;
		//if (correctPixel(pix43)) count += 1.0;

		//if (pix04.g > thresholdG && pix04.r < thresholdRB && pix04.b < thresholdRB) count += 1.0;
		//if (pix14.g > thresholdG && pix14.r < thresholdRB && pix14.b < thresholdRB) count += 1.0;
		//if (pix24.g > thresholdG && pix24.r < thresholdRB && pix24.b < thresholdRB) count += 1.0;
		//if (pix34.g > thresholdG && pix34.r < thresholdRB && pix34.b < thresholdRB) count += 1.0;
		//if (pix44.g > thresholdG && pix44.r < thresholdRB && pix44.b < thresholdRB) count += 1.0;

		// write count, and top left coordinates
		gl_FragColor = vec4(count, baseX, baseY, 1.0);
	}
</script>
<script id="shader-fs2" type="x-shader/x-fragment">
	precision highp float;

	uniform sampler2D texture;
	uniform float width;//w12
	uniform float height;//h12

	varying vec2 textureCoord;

	void main(void) {
		// current coordinates
		float x = floor(textureCoord.x * width);
		float y = floor(textureCoord.y * height);

		// base top left synthetic coordinates of given square
		// now working with smaller picture already so real coordinates are saved inside pixels
		float baseX = x - mod(x, 3.0);
		float baseY = y - mod(y, 3.0);

		// distance between 2 pixels
		vec2 diff = vec2(1.0/width, 1.0/height);

		// actual texture coordinates of top left pixel
		// + diff/2 because textureCoord is always between numbers
		vec2 baseTextureCoord = vec2(baseX / width + diff.x / 2.0, baseY / height + diff.y / 2.0);

		vec4 pix00 = texture2D(texture, vec2(baseTextureCoord.x, baseTextureCoord.y));
		vec4 pix10 = texture2D(texture, vec2(baseTextureCoord.x + diff.x, baseTextureCoord.y));
		vec4 pix20 = texture2D(texture, vec2(baseTextureCoord.x + 2.0*diff.x, baseTextureCoord.y));
		//vec4 pix30 = texture2D(texture, vec2(baseTextureCoord.x + 3.0*diff.x, baseTextureCoord.y));

		vec4 pix01 = texture2D(texture, vec2(baseTextureCoord.x, baseTextureCoord.y + diff.y));
		vec4 pix11 = texture2D(texture, vec2(baseTextureCoord.x + diff.x, baseTextureCoord.y + diff.y));
		vec4 pix21 = texture2D(texture, vec2(baseTextureCoord.x + 2.0*diff.x, baseTextureCoord.y + diff.y));
		//vec4 pix31 = texture2D(texture, vec2(baseTextureCoord.x + 3.0*diff.x, baseTextureCoord.y + diff.y));

		vec4 pix02 = texture2D(texture, vec2(baseTextureCoord.x, baseTextureCoord.y + 2.0*diff.y));
		vec4 pix12 = texture2D(texture, vec2(baseTextureCoord.x + diff.x, baseTextureCoord.y + 2.0*diff.y));
		vec4 pix22 = texture2D(texture, vec2(baseTextureCoord.x + 2.0*diff.x, baseTextureCoord.y + 2.0*diff.y));
		//vec4 pix32 = texture2D(texture, vec2(baseTextureCoord.x + 3.0*diff.x, baseTextureCoord.y + 2.0*diff.y));

		//vec4 pix03 = texture2D(texture, vec2(baseTextureCoord.x, baseTextureCoord.y + 3.0*diff.y));
		//vec4 pix13 = texture2D(texture, vec2(baseTextureCoord.x + diff.x, baseTextureCoord.y + 3.0*diff.y));
		//vec4 pix23 = texture2D(texture, vec2(baseTextureCoord.x + 2.0*diff.x, baseTextureCoord.y + 3.0*diff.y));
		//vec4 pix33 = texture2D(texture, vec2(baseTextureCoord.x + 3.0*diff.x, baseTextureCoord.y + 3.0*diff.y));

		float sumCount = pix00.r + pix10.r + pix20.r + pix01.r + pix11.r + pix21.r + pix02.r + pix12.r + pix22.r;
						//+ pix30.r + pix31.r + pix32.r + pix03.r + pix13.r + pix23.r + pix33.r;

		// no interesting pixels here
		// discard squares with one interesting pixel?
		if (sumCount < 2.0) discard;

		// weighted arithmetic mean of coordinates
		float sumX =
			pix00.r * pix00.g + pix10.r * pix10.g + pix20.r * pix20.g + //pix30.r * pix30.g +
			pix01.r * pix01.g + pix11.r * pix11.g + pix21.r * pix21.g + //pix31.r * pix31.g +
			pix02.r * pix02.g + pix12.r * pix12.g + pix22.r * pix22.g;// + pix32.r * pix32.g +
			//pix03.r * pix03.g + pix13.r * pix13.g + pix23.r * pix23.g + pix33.r * pix33.b;
		float meanX = sumX / sumCount;
		float sumY =
			pix00.r * pix00.b + pix10.r * pix10.b + pix20.r * pix20.b + //pix30.r * pix30.b +
			pix01.r * pix01.b + pix11.r * pix11.b + pix21.r * pix21.b + //pix31.r * pix31.b +
			pix02.r * pix02.b + pix12.r * pix12.b + pix22.r * pix22.b;// + pix32.r * pix32.b +
			//pix03.r * pix03.b + pix13.r * pix13.b + pix23.r * pix23.b + pix33.r * pix33.b;
		float meanY = sumY / sumCount;

		gl_FragColor = vec4(sumCount, meanX, meanY, 1.0);
	}
</script>
<script id="shader-fs-draw" type="x-shader/x-fragment">
	precision mediump float;

	uniform sampler2D texture;

	varying vec2 textureCoord;

	void main(void) {
		gl_FragColor = texture2D(texture, textureCoord);
	}
</script>
<script id="shader-vs" type="x-shader/x-vertex">
	attribute vec3 aVertexPosition;
	attribute vec2 aTextureCoord;

	uniform mat4 rotation;

	varying vec2 textureCoord;

	void main(void) {
		textureCoord = aTextureCoord;
		gl_Position = rotation * vec4(aVertexPosition, 1.0);
	}
</script>
<script type="text/javascript">
	"use strict";

	// HTMLVideoElement
	let video;
	// info if detection is being performed - if animation is running
	// also is used to make sure that animation is running only once
	let isAnimating = false;

	window.onload = function() {
		let initResult = Detection.init();

		if (!initResult) {
			alert("Your browser does not support WebGL.")
			document.querySelector(".loading").innerHTML = "Your browser does not support WebGL or some of its extensions.";
			return;
		}

		// set video listener, important for starting animation
		video = document.querySelector("video");
		video.addEventListener("canplaythrough", setupAfterVideoStreamIsReady, false);
		video.addEventListener("click", sendTouch, false);

		// set change and click listeners
		document.querySelector("label#all").addEventListener("click", doAll, false);
		document.querySelector("label#none").addEventListener("click", doNone, false);
		document.querySelector("label#position input").addEventListener("change", doPosition, false);
		document.querySelector("label#rotation input").addEventListener("change", doRotation, false);
		document.querySelector("label#motion input").addEventListener("change", doMotion, false);

		// window size listener for changing layout
		// checks which one of height or width is bigger and changes the layout appropriately
		window.addEventListener("resize", windowSizeChanged, false);
		windowSizeChanged();

		// init requestAnimFrame function
		Utils.initRequestAnimationFrame();

		// init Rotation object
		Rotation.init();
		// let the user know that the rotation of device is correct
		Rotation.setCustomFunction(function(data) {
			Helpers.checkRotation(data, function rotationToRight() {
				document.querySelector(".controls").style.backgroundColor = "lightblue";
			}, function rotationToLeft() {
				document.querySelector(".controls").style.backgroundColor = "lightblue";
			}, function noRotation() {
				document.querySelector(".controls").style.backgroundColor = "white";
			});
		});

		// init Motion object
		Motion.init();

		// https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia
		// get access to camera
		navigator.mediaDevices.getUserMedia({
			audio: false,
			video: { width: 1280, height: 720, facingMode: "environment" }
			/*video: {
				width: { min: 720, ideal: 1024, max: 1280 },
				height: { min: 540, max: 720 },
				//prefer rear camera
				facingMode: "environment"
			}*/
		}).then(function(stream) {
			video.srcObject = stream;
		}).catch(function(error) {
			let msg;
			if (error.name === "ConstraintNotSatisfiedError" || error.name === "NotFoundError") {
				msg = "Your camera does not meet required resolution for this application to work.";
			} else if (error.name === "TrackStartError") {
				msg = "Your camera is probably used by different application at this time.";
			} else {
				msg = "There was an unknown error when accessing your camera.";
			}
			document.querySelector(".loading").innerHTML = msg;
			alert(msg);
			console.log("%cVideo Error: " + error, 'color: red');
			console.log(msg);
		});
	};

	/**
	 * Main animation function that triggers detection in the image from camera
	 */
	function animate() {
		if (isAnimating) {
			Detection.updateTexture(video);
			Detection.repaint();
			requestAnimFrame(animate);
		}
	}

	/**
	 * Event handler when camera is ready to give pictures
	 */
	function setupAfterVideoStreamIsReady() {
		Detection.setupAfterVideoStreamIsReady(video.videoWidth, video.videoHeight);

		// hide loading message
		document.querySelector(".loading-container").classList.add("hidden");
		document.querySelector(".main").classList.remove("hidden");

		test(0, 139);
	}

	function test(start, end) {
		let loaded = 0;
		const data = [];
		Utils.getDataFromFile("/python/new/test.txt", (text) => {
			const testData = text.split("\r\n")
					.map(t => t.split(","))
					.filter(t => t[0] !== "")
					.map(t => [t[0], t[1] * 1, t[2] * 1, t[3] / 360, t[4] / 100, t[5] / 100])
					.sort((a, b) => a[0] <= b[0] ? -1 : 1);

			for (let i = start; i <= end; i++) {
				const name = String(i).padStart(3, "0");
				const img = new Image();
				img.onload = () => {
					const hsv = testData[i];
					const rgb = HSVtoRGB(hsv[3], hsv[4], hsv[5]);
					// console.log(rgb);
					Detection.setExternalColor(rgb);
					Detection.setupAfterVideoStreamIsReady(img.width, img.height);
					Detection.updateTexture(img);
					Detection.repaint();
					const readData = Detection.getReadBuffer2();
					if (readData[0] === 0 && readData[1] === 0) {
						data.push(name + ".jpg,-1,-1");
					} else {
						data.push(name + ".jpg," + readData[0] + "," + readData[1]);
					}
					loaded++;
				};
				img.src = "/python/new/" + name + ".jpg";
			}
		});
		const total = end + 1;
		const interval = function() {
			if (loaded < total) {
				setTimeout(interval, 50);
			} else {
				console.log(data.sort().reduce((a, b) => a + "\n" + b))
			}
		};
		setTimeout(interval, 1);
	}

	function HSVtoRGB(h, s, v) {
		let r, g, b;
		if (arguments.length === 1) {
			s = h.s; v = h.v; h = h.h;
		}
		const i = Math.floor(h * 6);
		const f = h * 6 - i;
		const p = v * (1 - s);
		const q = v * (1 - f * s);
		const t = v * (1 - (1 - f) * s);
		switch (i % 6) {
			case 0:
				r = v; g = t; b = p;
				break;
			case 1:
				r = q; g = v; b = p;
				break;
			case 2:
				r = p; g = v; b = t;
				break;
			case 3:
				r = p; g = q; b = v;
				break;
			case 4:
				r = t; g = p; b = v;
				break;
			case 5:
				r = v; g = p; b = q;
				break;
		}
		// return [
		// 	Math.round(r * 255),
		// 	Math.round(g * 255),
		// 	Math.round(b * 255)
		// ];
		return [r, g, b];
	}

	/**
	 * Event handler for starting all operations
	 */
	function doAll() {
		document.querySelector("#all").classList.add("pulse");
		setTimeout(function() {
			document.querySelector("#all").classList.remove("pulse");
		}, 600);

		document.querySelector("label#position input").checked = true;
		document.querySelector("label#rotation input").checked = true;
		document.querySelector("label#motion input").checked = true;
		doPosition();
		doRotation();
		doMotion();
	}

	/**
	 * Event handler for stopping all operations
	 */
	function doNone() {
		document.querySelector("#none").classList.add("pulse");
		setTimeout(function() {
			document.querySelector("#none").classList.remove("pulse");
		}, 600);

		document.querySelector("label#position input").checked = false;
		document.querySelector("label#rotation input").checked = false;
		document.querySelector("label#motion input").checked = false;
		doPosition();
		doRotation();
		doMotion();
	}

	/**
	 * Event handler when position button is clicked
	 */
	function doPosition() {
		if (document.querySelector("label#position input").checked) {
			document.querySelector("label#position").classList.add("active");
			if (!isAnimating) {
				isAnimating = true;
				Detection.restart();
				animate();
			}
		} else {
			document.querySelector("label#position").classList.remove("active");
			Detection.finish();
			isAnimating = false;
		}
	}

	/**
	 * Event handler when rotation button is clicked
	 */
	function doRotation() {
		if (document.querySelector("label#rotation input").checked) {
			document.querySelector("label#rotation").classList.add("active");
			Rotation.start();
		} else {
			document.querySelector("label#rotation").classList.remove("active");
			Rotation.finish();
		}
	}

	/**
	 * Event handler when motion button is clicked
	 */
	function doMotion() {
		if (document.querySelector("label#motion input").checked) {
			document.querySelector("label#motion").classList.add("active");
			Motion.start();
		} else {
			document.querySelector("label#motion").classList.remove("active");
			Motion.finish();
		}
	}

	/**
	 * Resize event handler
	 * Changes GUI so that buttons are either right or bottom
	 */
	function windowSizeChanged() {
		if (window.innerHeight < window.innerWidth) {
			// window is wider than higher
			document.querySelector(".main").classList.remove("bottom");
			document.querySelector(".main").classList.add("right");
		} else {
			// window is higher than wider
			document.querySelector(".main").classList.remove("right");
			document.querySelector(".main").classList.add("bottom");
		}
	}

	/**
	 * Click and touch event handler
	 * Sends information that the video has been clicked or touched
	 */
	function sendTouch() {
		let obj = {
			type: "touch",
			time: new Date().getTime()
		};
		Sender.add(obj);
	}

	/**
	 * Helper method for sending test data
	 */
	function testSend() {
		let request = new XMLHttpRequest();
		request.open('POST', '/ajax/data');
		request.setRequestHeader("Content-Type", "application/json;charset=UTF-8");
		let data = [{
			type: "test",
			time: new Date().getTime()
		}];
		request.send(JSON.stringify(data));
	}

</script>

</head>
<body>
<div class="loading-container">
	<div class="loading">
		Loading, please wait...<br>
		Access to your camera is required for this application to work.<br>
		You might be asked for giving a permission to access it.
	</div>
</div>
<div class="main hidden">
	<div class="center">
		<canvas></canvas>
		<video src="" autoplay muted></video>
	</div>
	<div class="controls">
		<label id="all">Check all</label><br>
		<label id="none">Uncheck all</label><br>
		<hr>
		<label id="position"><input type="checkbox"> Position</label><br>
		<label id="rotation"><input type="checkbox"> Rotation</label><br>
		<label id="motion"><input type="checkbox"> Motion</label>
	</div>
</div>
</body>
</html>
